{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_textgen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihwrnN1uctAa"
      },
      "source": [
        "import numpy\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DSJ0GJZnVdt",
        "outputId": "98a64238-984e-4332-a32b-2db6f874db6e"
      },
      "source": [
        "filename = \"aliceinwonderland.txt\"\r\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\r\n",
        "raw_text = raw_text.lower()\r\n",
        "\r\n",
        "chars = sorted(list(set(raw_text)))\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\r\n",
        "\r\n",
        "n_chars = len(raw_text)\r\n",
        "n_vocab = len(chars)\r\n",
        "print (\"Total Characters: \", n_chars)\r\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144430\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UywNY-DYocUV",
        "outputId": "0ba2670d-3ac0-49fa-9af1-b461bdec0a31"
      },
      "source": [
        "seq_length = 100\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for i in range(0, n_chars - seq_length, 1):\r\n",
        "\tseq_in = raw_text[i:i + seq_length]\r\n",
        "\tseq_out = raw_text[i + seq_length]\r\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\r\n",
        "\tdataY.append(char_to_int[seq_out])\r\n",
        "n_patterns = len(dataX)\r\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h8CCWX8odTC"
      },
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\r\n",
        "X = X / float(n_vocab)\r\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_DdIhYoda1"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAHxD79aoddi"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JcfxsGBodgi",
        "outputId": "d8a29793-c46e-44de-84a2-05ef7f387e93"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1128/1128 [==============================] - 21s 12ms/step - loss: 3.0556\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.97048, saving model to weights-improvement-01-2.9705.hdf5\n",
            "Epoch 2/20\n",
            "1128/1128 [==============================] - 14s 12ms/step - loss: 2.8018\n",
            "\n",
            "Epoch 00002: loss improved from 2.97048 to 2.77457, saving model to weights-improvement-02-2.7746.hdf5\n",
            "Epoch 3/20\n",
            "1128/1128 [==============================] - 14s 12ms/step - loss: 2.6975\n",
            "\n",
            "Epoch 00003: loss improved from 2.77457 to 2.67838, saving model to weights-improvement-03-2.6784.hdf5\n",
            "Epoch 4/20\n",
            "1128/1128 [==============================] - 14s 12ms/step - loss: 2.6123\n",
            "\n",
            "Epoch 00004: loss improved from 2.67838 to 2.59609, saving model to weights-improvement-04-2.5961.hdf5\n",
            "Epoch 5/20\n",
            "1128/1128 [==============================] - 14s 12ms/step - loss: 2.5392\n",
            "\n",
            "Epoch 00005: loss improved from 2.59609 to 2.52676, saving model to weights-improvement-05-2.5268.hdf5\n",
            "Epoch 6/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.4763\n",
            "\n",
            "Epoch 00006: loss improved from 2.52676 to 2.46932, saving model to weights-improvement-06-2.4693.hdf5\n",
            "Epoch 7/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.4224\n",
            "\n",
            "Epoch 00007: loss improved from 2.46932 to 2.41716, saving model to weights-improvement-07-2.4172.hdf5\n",
            "Epoch 8/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.3740\n",
            "\n",
            "Epoch 00008: loss improved from 2.41716 to 2.36767, saving model to weights-improvement-08-2.3677.hdf5\n",
            "Epoch 9/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.3210\n",
            "\n",
            "Epoch 00009: loss improved from 2.36767 to 2.32043, saving model to weights-improvement-09-2.3204.hdf5\n",
            "Epoch 10/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.2768\n",
            "\n",
            "Epoch 00010: loss improved from 2.32043 to 2.27779, saving model to weights-improvement-10-2.2778.hdf5\n",
            "Epoch 11/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.2380\n",
            "\n",
            "Epoch 00011: loss improved from 2.27779 to 2.23706, saving model to weights-improvement-11-2.2371.hdf5\n",
            "Epoch 12/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.2006\n",
            "\n",
            "Epoch 00012: loss improved from 2.23706 to 2.19820, saving model to weights-improvement-12-2.1982.hdf5\n",
            "Epoch 13/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.1491\n",
            "\n",
            "Epoch 00013: loss improved from 2.19820 to 2.16134, saving model to weights-improvement-13-2.1613.hdf5\n",
            "Epoch 14/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.1189\n",
            "\n",
            "Epoch 00014: loss improved from 2.16134 to 2.12396, saving model to weights-improvement-14-2.1240.hdf5\n",
            "Epoch 15/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.0787\n",
            "\n",
            "Epoch 00015: loss improved from 2.12396 to 2.08895, saving model to weights-improvement-15-2.0890.hdf5\n",
            "Epoch 16/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.0536\n",
            "\n",
            "Epoch 00016: loss improved from 2.08895 to 2.05722, saving model to weights-improvement-16-2.0572.hdf5\n",
            "Epoch 17/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 2.0113\n",
            "\n",
            "Epoch 00017: loss improved from 2.05722 to 2.02316, saving model to weights-improvement-17-2.0232.hdf5\n",
            "Epoch 18/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 1.9785\n",
            "\n",
            "Epoch 00018: loss improved from 2.02316 to 1.99389, saving model to weights-improvement-18-1.9939.hdf5\n",
            "Epoch 19/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 1.9503\n",
            "\n",
            "Epoch 00019: loss improved from 1.99389 to 1.96425, saving model to weights-improvement-19-1.9643.hdf5\n",
            "Epoch 20/20\n",
            "1128/1128 [==============================] - 14s 13ms/step - loss: 1.9267\n",
            "\n",
            "Epoch 00020: loss improved from 1.96425 to 1.94104, saving model to weights-improvement-20-1.9410.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c2e2db860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YUXqYDrq0mc",
        "outputId": "39c85ccf-fe5b-4f67-b8b8-cc8ff9d5dc51"
      },
      "source": [
        "filename = \"weights-improvement-20-1.9410.hdf5\"\r\n",
        "model.load_weights(filename)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\r\n",
        "\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\r\n",
        "start = numpy.random.randint(0, len(dataX)-1)\r\n",
        "pattern = dataX[start]\r\n",
        "print (\"Seed:\")\r\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\r\n",
        "# generate characters\r\n",
        "generated_text = \"\"\r\n",
        "for i in range(1000):\r\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "\tx = x / float(n_vocab)\r\n",
        "\tprediction = model.predict(x, verbose=0)\r\n",
        "\tindex = numpy.argmax(prediction)\r\n",
        "\tresult = int_to_char[index]\r\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\r\n",
        "\tgenerated_text = generated_text + result\r\n",
        "\tpattern.append(index)\r\n",
        "\tpattern = pattern[1:len(pattern)]\r\n",
        "print(generated_text)\r\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" till sobbing a little now and then, 'we went to school in the\n",
            "sea. the master was an old turtle--we  \"\n",
            "teal thet io the medster oo the canke  \n",
            "\n",
            "than she horst san in the siness, a dott on knwt nhee,' said the monk turtllf. ''then'' said the monk turtllf. 'io sou to tele toeng to that toued ie den eeone the woile  \n",
            "\n",
            "the morse of the sas ano the wiile ras in the mintter,' she said to herself, 'io s soeael to tee   \n",
            "the sai oo teiy lo tou dlo that the sase oi the court. \n",
            "\n",
            "'whu,  said the monke \n",
            "'ie tou th tee thet ' shought alice, 'io s a lertee of thi wan of the goose   \n",
            "'io, toe sai oo the saassn ' she mock turtle seil on a gintee oone, and whnt an in oame, and sas aoing in a lona thle so the whut siatey  she was to tin the had so tee that shue the soide   the cate pas noen a cittee toice \n",
            "'what soued bad neter the sooee of the ran-'\n",
            "\n",
            "'iice you kave oo hnt a cit oi toe kone,' said the monk turtllf. 'io sou to tele toeng to that toued iere to the sooe. \n",
            "\n",
            "'i c gateer would ' said the morke  shi had never here   she said to herself, 'io s soeakl tou meke to be ir the to taak the mooe tf the\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}